"""Run a single specialized Stock Research agent without the lead coordinator."""

import argparse
import asyncio
import os
from datetime import datetime
from pathlib import Path

import yfinance as yf
from dotenv import load_dotenv
from claude_agent_sdk import (
    ClaudeSDKClient,
    ClaudeAgentOptions,
    HookMatcher,
    ResultMessage,
)

from utils.message_handler import process_assistant_message
from utils.subagent_tracker import SubagentTracker
from utils.transcript import setup_session, TranscriptWriter
from tools.sec_agent_tool import SECAgentTool, build_sec_mcp_server
from preprocess_sec import preprocess_ticker

PROMPTS_DIR = Path(__file__).parent / "prompts"

AGENT_PRESETS = {
    "history": {
        "prompt_file": "history_researcher.txt",
        "tools": [
            "WebSearch",
            "Write",
            "Read",
            "get_company_filings",
            "get_financial_snapshot",
            "extract_sec_sections",
        ],
        "task_template": (
            "Research the full company history for {ticker} and save concise notes to "
            "files/{ticker}/notes/history.md following the required format."
        ),
        "ensure_notes_dir": True,
    },
    "deep-history": {
        "prompt_file": "deep_history_researcher.txt",
        "tools": [
            "WebSearch",
            "Write",
            "Read",
            "Glob",
            "get_financial_snapshot",
            "extract_sec_sections",
        ],
        "task_template": (
            "å¯¹ {ticker} è¿›è¡Œæ·±åº¦å†å²ç ”ç©¶ï¼Œéµå¾ª 3 é˜¶æ®µæ–¹æ³•è®ºï¼š"
            "(1) å…ˆè¯»å– files/{ticker}/_index.json å’Œ raw/*.md é¢„å¤„ç†æ–‡ä»¶ï¼Œæ„å»ºæ—¶é—´çº¿ï¼›"
            "(2) è°ƒæŸ¥ 2-3 ä¸ªé‡è¦ç–‘ç‚¹ï¼›"
            "(3) ç»¼åˆè¾“å‡ºå®Œæ•´æ—¶é—´çº¿å’Œæ¼”è¿›åˆ†æï¼ˆä¸­æ–‡ï¼‰ã€‚"
            "æ‰€æœ‰è¾“å‡ºä¿å­˜åˆ° files/{ticker}/notes/deep-history/ã€‚"
        ),
        "ensure_notes_dir": True,
        "needs_preprocessing": True,
    },
    "business": {
        "prompt_file": "business_researcher.txt",
        "tools": ["WebSearch", "Write"],
        "task_template": (
            "Research the business model, revenue drivers, and competitive position for {ticker}. "
            "Save concise notes to files/{ticker}/notes/business.md following the required format."
        ),
        "ensure_notes_dir": True,
    },
    "deep-business": {
        "prompt_file": "deep_business_researcher.txt",
        "tools": [
            "WebSearch",
            "Write",
            "Read",
            "Glob",
            "get_financial_snapshot",
            "extract_sec_sections",
        ],
        "task_template": (
            "å¯¹ {ticker} è¿›è¡Œå•†ä¸šæ¨¡å¼æ·±åº¦ç ”ç©¶ï¼š"
            "(1) å…ˆè¯»å– files/{ticker}/_index.json å’Œ raw/*.md é¢„å¤„ç†æ–‡ä»¶ï¼›"
            "(2) æŒ‰ 9 ä¸ªæ¨¡å—åˆ†æå•†ä¸šæ¨¡å¼ï¼ˆä»·å€¼ä¸»å¼ ã€äº§å“ã€å®¢æˆ·ã€è¿è¥ã€ç›ˆåˆ©ã€ç”Ÿæ„ç‰¹æ€§ã€æ ¸å¿ƒèƒ½åŠ›ã€è§„æ¨¡åŒ–ã€é£é™©ï¼‰ï¼›"
            "(3) è¾“å‡ºåˆ° files/{ticker}/notes/business-model/business_model.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
        "needs_preprocessing": True,
    },
    "organization": {
        "prompt_file": "org_researcher.txt",
        "tools": ["WebSearch", "Write"],
        "task_template": (
            "Research the leadership team, board, and ownership structure for {ticker}. "
            "Save concise notes to files/{ticker}/notes/organization.md following the required format."
        ),
        "ensure_notes_dir": True,
    },
    "report": {
        "prompt_file": "report_writer.txt",
        "tools": ["Glob", "Read", "Write"],
        "task_template": (
            "Read all research notes inside files/{ticker}/notes/ and synthesize the official "
            "Investment Memo for {ticker}, saving it to files/{ticker}/report.md."
        ),
        "ensure_notes_dir": False,
    },
    "deep-industrial": {
        "prompt_file": "deep_industrial_researcher.txt",
        "tools": [
            "WebSearch",
            "Write",
            "Read",
            "Glob",
        ],
        "task_template": (
            "å¯¹ {ticker} æ‰€åœ¨è¡Œä¸šè¿›è¡Œæ·±åº¦ç ”ç©¶ï¼Œéµå¾ª 3 å±‚é€’è¿›æ–¹æ³•è®ºï¼š"
            "(1) ç¬¬ 1 å±‚ï¼šèµ›é“ç”»åƒï¼ˆæ˜¯ä»€ä¹ˆï¼‰â†’ è¾“å‡º layer1_landscape.mdï¼›"
            "(2) ç¬¬ 2 å±‚ï¼šè¿è¡Œæœºåˆ¶ï¼ˆä¸ºä»€ä¹ˆï¼‰â†’ è¾“å‡º layer2_mechanism.mdï¼›"
            "(3) ç¬¬ 3 å±‚ï¼šæŠ•èµ„åˆ¤æ–­ï¼ˆæ‰€ä»¥å‘¢ï¼‰â†’ è¾“å‡º layer3_judgment.mdã€‚"
            "æ‰€æœ‰æ–‡ä»¶ä¿å­˜åˆ° files/{ticker}/notes/industry/ï¼ˆä¸­æ–‡æ’°å†™ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
    # ==================== View Agents ====================
    "view-order": {
        "prompt_file": "view/è§‚ç‚¹_ç§©åº.md",
        "tools": ["Read", "Write"],
        "task_template": (
            "åŸºäºä»¥ä¸‹ 3 ä¸ªç²¾ç®€ç‰ˆæ–‡ä»¶å¯¹ {ticker} è¿›è¡Œç§©åºåˆ†ææ¡†æ¶è¯„ä¼°ï¼š\n"
            "1. files/{ticker}/notes/business-model/_summary.mdï¼ˆå•†ä¸šæ¨¡å¼æ‘˜è¦ï¼‰\n"
            "2. files/{ticker}/notes/deep-history/_summary.mdï¼ˆå†å²æ¼”è¿›æ‘˜è¦ï¼‰\n"
            "3. files/{ticker}/notes/industry/_summary.mdï¼ˆè¡Œä¸šåˆ†ææ‘˜è¦ï¼‰\n\n"
            "åªè¯»å–è¿™ 3 ä¸ªæ–‡ä»¶ï¼Œä¸è¦è¯»å–å…¶ä»–æ–‡ä»¶ã€‚"
            "è¯†åˆ«å…¶åˆ›ç”Ÿå…¬å¼ã€æƒåŠ›åœºå¼ºåº¦ã€åå¡Œä½ç½®å’ŒèŒƒå¼è„†å¼±æ€§ï¼Œ"
            "æœ€ç»ˆç»™å‡ºã€Œæ¢è¿˜æ˜¯ä¸æ¢ã€çš„å‹å€’æ€§åˆ¤æ–­ã€‚"
            "è¾“å‡ºä¿å­˜åˆ° files/{ticker}/notes/views/view_order.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
    "view-7powers": {
        "prompt_file": "view/è§‚ç‚¹_7powers.md",
        "tools": ["Read", "Write"],
        "task_template": (
            "åŸºäºä»¥ä¸‹ 2 ä¸ªç²¾ç®€ç‰ˆæ–‡ä»¶å¯¹ {ticker} è¿›è¡Œ 7 Powers æ¡†æ¶è¯„ä¼°ï¼š\n"
            "1. files/{ticker}/notes/business-model/_summary.mdï¼ˆå•†ä¸šæ¨¡å¼æ‘˜è¦ï¼‰\n"
            "2. files/{ticker}/notes/industry/_summary.mdï¼ˆè¡Œä¸šåˆ†ææ‘˜è¦ï¼‰\n\n"
            "åªè¯»å–è¿™ 2 ä¸ªæ–‡ä»¶ï¼Œä¸è¦è¯»å–å…¶ä»–æ–‡ä»¶ã€‚"
            "ä¸¥æ ¼æŒ‰ç…§ prompt ä¸­çš„è¾“å‡ºæ¨¡æ¿æ ¼å¼è¾“å‡ºï¼Œä¸è¦å±•å¼€è¯¦ç»†åˆ†æã€‚"
            "è¾“å‡ºä¿å­˜åˆ° files/{ticker}/notes/views/view_7powers.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
    "view-ecology": {
        "prompt_file": "view/è§‚ç‚¹_ç”Ÿæ€çŒæ‰‹.md",
        "tools": ["Read", "Write"],
        "task_template": (
            "åŸºäºä»¥ä¸‹ 3 ä¸ªç²¾ç®€ç‰ˆæ–‡ä»¶å¯¹ {ticker} è¿›è¡Œç”Ÿæ€ä½çŒæ‰‹åˆ†æï¼š\n"
            "1. files/{ticker}/notes/business-model/_summary.mdï¼ˆå•†ä¸šæ¨¡å¼æ‘˜è¦ï¼‰\n"
            "2. files/{ticker}/notes/industry/_summary.mdï¼ˆè¡Œä¸šåˆ†ææ‘˜è¦ï¼‰\n"
            "3. files/{ticker}/notes/deep-history/_summary.mdï¼ˆå†å²æ¼”è¿›æ‘˜è¦ï¼‰\n\n"
            "åªè¯»å–è¿™ 3 ä¸ªæ–‡ä»¶ï¼Œä¸è¦è¯»å–å…¶ä»–æ–‡ä»¶ã€‚"
            "è§£ç ï¼šä½ç½®çœŸç›¸ã€ä»·å€¼é€»è¾‘ã€æ­»äº¡å€’è®¡æ—¶ã€è¿›åŒ–å¼•æ“ï¼Œ"
            "æœ€ç»ˆå›ç­”ï¼šè¿™æ˜¯æ­£åœ¨å˜å¼ºçš„æ•é£Ÿè€…ï¼Œè¿˜æ˜¯æ­£åœ¨å˜è‚¥çš„çŒç‰©ï¼Ÿ"
            "è¾“å‡ºä¿å­˜åˆ° files/{ticker}/notes/views/view_ecology.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
    "view-genesis": {
        "prompt_file": "view/è§‚ç‚¹_åˆ›ç”Ÿå…¬å¼.md",
        "tools": ["Read", "Write"],
        "task_template": (
            "åŸºäºä»¥ä¸‹ 2 ä¸ªç²¾ç®€ç‰ˆæ–‡ä»¶å¯¹ {ticker} è¿›è¡Œã€Œçœ‹ç›¸çš„è‰ºæœ¯ã€åˆ†æï¼š\n"
            "1. files/{ticker}/notes/business-model/_summary.mdï¼ˆå•†ä¸šæ¨¡å¼æ‘˜è¦ï¼‰\n"
            "2. files/{ticker}/notes/industry/_summary.mdï¼ˆè¡Œä¸šåˆ†ææ‘˜è¦ï¼‰\n\n"
            "åªè¯»å–è¿™ 2 ä¸ªæ–‡ä»¶ï¼Œä¸è¦è¯»å–å…¶ä»–æ–‡ä»¶ã€‚"
            "è¯†åˆ«åˆ›ç”Ÿå…¬å¼ã€è¯„ä¼°æƒåŠ›åœºã€å®šä½æ–°ç¨€ç¼ºã€åˆ¤æ–­è®¤çŸ¥æŠ˜ä»·ï¼Œ"
            "å›ç­”è¿™å®¶å…¬å¸æ˜¯å¦ä»£è¡¨ã€Œå‹å€’æ€§çš„æ›´é«˜å“è´¨ç§©åºç³»ç»Ÿã€ã€‚"
            "è¾“å‡ºä¿å­˜åˆ° files/{ticker}/notes/views/view_genesis.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
    # ==================== Summary Agent ====================
    "summary": {
        "prompt_file": "summary_agent.txt",
        "tools": ["Read", "Write"],
        "task_template": (
            "ç»¼åˆ {ticker} çš„çŸ¥è¯†åº“å’Œè§‚ç‚¹åˆ†æï¼Œç”ŸæˆæŠ•èµ„å¤‡å¿˜å½•ã€‚\n"
            "**é‡è¦**ï¼šè¯·ä½¿ç”¨ç²¾ç®€ç‰ˆæ–‡ä»¶ä»¥å‡å°‘ token æ¶ˆè€—ï¼Œä¾æ¬¡è¯»å–ä»¥ä¸‹ 7 ä¸ªæ–‡ä»¶ï¼š\n"
            "ã€çŸ¥è¯†åº“ç²¾ç®€ç‰ˆã€‘\n"
            "1. files/{ticker}/notes/business-model/_summary.mdï¼ˆå•†ä¸šæ¨¡å¼æ‘˜è¦ï¼‰\n"
            "2. files/{ticker}/notes/industry/_summary.mdï¼ˆè¡Œä¸šåˆ†ææ‘˜è¦ï¼‰\n"
            "3. files/{ticker}/notes/deep-history/_summary.mdï¼ˆå†å²æ¼”è¿›æ‘˜è¦ï¼‰\n"
            "ã€è§‚ç‚¹å±‚è¾“å‡ºã€‘\n"
            "4. files/{ticker}/notes/views/view_7powers.md\n"
            "5. files/{ticker}/notes/views/view_order.md\n"
            "6. files/{ticker}/notes/views/view_ecology.md\n"
            "7. files/{ticker}/notes/views/view_genesis.md\n\n"
            "äº¤å‰éªŒè¯å„æ¥æºçš„ç»“è®ºï¼Œè¯†åˆ«å…±è¯†å’Œåˆ†æ­§ã€‚\n"
            "è¾“å‡ºæ§åˆ¶åœ¨ 150 è¡Œä»¥å†…ï¼Œä¿å­˜åˆ° files/{ticker}/notes/investment_memo.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
    # ==================== Challenge Agent ====================
    "challenge": {
        "prompt_file": "challenge_agent.txt",
        "tools": ["Read", "Write", "Glob"],
        "task_template": (
            "**é‡è¦**ï¼šæ–‡ä»¶è·¯å¾„å·²æ˜ç¡®æŒ‡å®šï¼Œè¯·ç›´æ¥ä½¿ç”¨ Read å·¥å…·è¯»å– {ticker} çš„æŠ•èµ„å¤‡å¿˜å½• files/{ticker}/notes/investment_memo.mdï¼Œæ— éœ€ä½¿ç”¨ Glob æœç´¢ã€‚\n"
            "è¿ç”¨åœ†æ¡Œæ€æƒ³å®¶æ¡†æ¶å¯¹å…¶æ ¸å¿ƒç»“è®ºå‘èµ·æ·±åº¦æŒ‘æˆ˜ä¸è®¨è®ºã€‚\n"
            "é‡ç‚¹å®¡è§†ï¼šå‰æå‡è®¾ã€é€»è¾‘é“¾æ¡ã€æ ¸å¿ƒçŸ›ç›¾ã€æ½œåœ¨ç›²ç‚¹ã€‚\n"
            "è¾“å‡ºä¿å­˜åˆ° files/{ticker}/notes/investment_memo_challenge.mdï¼ˆä¸­æ–‡ï¼‰ã€‚"
        ),
        "ensure_notes_dir": True,
    },
}


def write_session_notes(
    base_dir: Path,
    agent_key: str,
    ticker: str,
    task_prompt: str,
    model: str,
    session_dir: Path,
    transcript_file: Path,
):
    """Persist a copy of the session transcript into files/{ticker}/logs."""
    logs_dir = base_dir / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)

    session_name = session_dir.name
    timestamp_label = (
        session_name.split("session_", 1)[1]
        if session_name.startswith("session_")
        else datetime.now().strftime("%Y%m%d_%H%M%S")
    )

    note_path = logs_dir / f"{agent_key}_{timestamp_label}.md"

    try:
        transcript_text = transcript_file.read_text(encoding="utf-8", errors="replace")
    except FileNotFoundError:
        transcript_text = ""

    instruction_block = (
        "\n".join(f"> {line}" for line in task_prompt.strip().splitlines())
        or "> (none)"
    )

    content = (
        f"# {ticker} {agent_key} ä¼šè¯è®°å½•\n\n"
        f"- Timestamp: {timestamp_label}\n"
        f"- Model: {model}\n"
        f"- Session logs: {session_dir}\n"
        f"- Instruction:\n\n"
        f"{instruction_block}\n\n"
        "## Transcript\n\n"
        f"{transcript_text.strip()}\n"
    )

    note_path.write_text(content, encoding="utf-8")
    print(f"Session log saved to {note_path.resolve()}")


def load_prompt(filename: str) -> str:
    prompt_path = PROMPTS_DIR / filename
    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read().strip()


def get_stock_data(ticker: str) -> dict:
    """è·å–è‚¡ç¥¨å®æ—¶æ•°æ®ï¼ˆä»·æ ¼ã€å¸‚å€¼ï¼‰ã€‚

    Returns:
        dict: {"price": float|None, "market_cap": float|None, "currency": str}
    """
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        price = info.get("currentPrice") or info.get("regularMarketPrice")
        market_cap = info.get("marketCap")
        currency = info.get("currency", "USD")
        return {
            "price": price,
            "market_cap": market_cap,
            "currency": currency,
        }
    except Exception as e:
        print(f"âš ï¸ è·å– {ticker} è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return {"price": None, "market_cap": None, "currency": "USD"}


def format_market_cap(value: float | None) -> str:
    """æ ¼å¼åŒ–å¸‚å€¼æ˜¾ç¤ºã€‚"""
    if value is None:
        return "æ•°æ®å¾…æ›´æ–°"
    if value >= 1e12:
        return f"{value / 1e12:.2f}T"
    elif value >= 1e9:
        return f"{value / 1e9:.2f}B"
    elif value >= 1e6:
        return f"{value / 1e6:.2f}M"
    else:
        return f"{value:,.0f}"


def get_recent_news(ticker: str, max_items: int = 5) -> str:
    """è·å–æœ€æ–°æ–°é—»ä½œä¸ºæ—¶é—´é”šç‚¹ã€‚

    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        max_items: æœ€å¤šè¿”å›çš„æ–°é—»æ¡æ•°

    Returns:
        æ ¼å¼åŒ–çš„æ–°é—»åˆ—è¡¨å­—ç¬¦ä¸²
    """
    try:
        stock = yf.Ticker(ticker)
        news = stock.news[:max_items] if stock.news else []

        if not news:
            return "æš‚æ— æœ€æ–°æ–°é—»"

        lines = []
        for item in news:
            title = item.get("title", "")
            # yfinance çš„æ—¶é—´æˆ³æ˜¯ Unix timestamp
            pub_time = item.get("providerPublishTime", 0)
            if pub_time:
                pub_date = datetime.fromtimestamp(pub_time).strftime("%Y-%m-%d %H:%M")
            else:
                pub_date = "æœªçŸ¥æ—¥æœŸ"
            publisher = item.get("publisher", "")
            lines.append(f"- [{pub_date}] {title} ({publisher})")

        return "\n".join(lines)
    except Exception as e:
        print(f"âš ï¸ è·å– {ticker} æ–°é—»å¤±è´¥: {e}")
        return "æ–°é—»è·å–å¤±è´¥"


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Run a single Stock Research agent. "
            "Profile agents: history, deep-history, business, deep-business, organization, deep-industrial. "
            "View agents: view-order, view-7powers, view-ecology, view-genesis. "
            "Synthesis: report."
        )
    )
    parser.add_argument(
        "--agent",
        choices=list(AGENT_PRESETS.keys()),
        required=True,
        help="Which agent to run.",
    )
    parser.add_argument(
        "--ticker",
        help="Ticker symbol, e.g., NVDA. If omitted, you will be prompted.",
    )
    parser.add_argument(
        "--model",
        default="haiku",
        help="Claude model ID to use (default: haiku).",
    )
    parser.add_argument(
        "--instruction",
        help="Override the default task instruction sent to the agent.",
    )
    return parser.parse_args()


def ensure_directories(ticker: str, ensure_notes_dir: bool) -> Path:
    base_dir = Path("files") / ticker
    notes_dir = base_dir / "notes"
    base_dir.mkdir(parents=True, exist_ok=True)
    if ensure_notes_dir:
        notes_dir.mkdir(exist_ok=True)
    return base_dir


def ensure_preprocessing(ticker: str, base_dir: Path) -> bool:
    """
    æ£€æŸ¥å¹¶æ‰§è¡Œ SEC æ–‡ä»¶é¢„å¤„ç†ã€‚

    Returns:
        True if preprocessing was run, False if already exists
    """
    index_file = base_dir / "_index.json"
    raw_dir = base_dir / "raw"

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰é¢„å¤„ç†æ–‡ä»¶
    if index_file.exists() and raw_dir.exists() and any(raw_dir.iterdir()):
        print(f"âœ“ é¢„å¤„ç†æ–‡ä»¶å·²å­˜åœ¨: {base_dir}")
        return False

    print(f"\nğŸ“¥ è‡ªåŠ¨é¢„å¤„ç† {ticker} çš„ SEC æ–‡ä»¶...")
    preprocess_ticker(ticker, filing_types=["10-K", "10-Q", "DEF 14A"], verbose=True)
    return True


async def run_agent(agent_key: str, ticker: str, model: str, instruction: str | None):
    config = AGENT_PRESETS[agent_key]
    prompt = load_prompt(config["prompt_file"])

    # è·å–å®æ—¶è‚¡ç¥¨æ•°æ®ï¼ˆä»·æ ¼ã€å¸‚å€¼ï¼‰
    print(f"ğŸ“ˆ è·å– {ticker} å®æ—¶æ•°æ®...")
    stock_data = get_stock_data(ticker)
    price_str = f"{stock_data['price']:.2f}" if stock_data["price"] else "æ•°æ®å¾…æ›´æ–°"
    market_cap_str = format_market_cap(stock_data["market_cap"])
    current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

    # è·å–æœ€æ–°æ–°é—»ä½œä¸ºæ—¶é—´é”šç‚¹
    print(f"ğŸ“° è·å– {ticker} æœ€æ–°æ–°é—»...")
    recent_news = get_recent_news(ticker)

    # æ›¿æ¢æ‰€æœ‰å ä½ç¬¦
    prompt = prompt.replace("{TICKER}", ticker)
    prompt = prompt.replace("{DATE}", current_date)
    prompt = prompt.replace("{PRICE}", price_str)
    prompt = prompt.replace("{MARKET_CAP}", market_cap_str)
    prompt = prompt.replace("{RECENT_NEWS}", recent_news)

    # For deep-industrial agent, don't replace {INDUSTRY} - let agent identify it
    if agent_key != "deep-industrial":
        prompt = prompt.replace("{INDUSTRY}", ticker)
    base_dir = ensure_directories(ticker, config["ensure_notes_dir"])

    # è‡ªåŠ¨é¢„å¤„ç† SEC æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if config.get("needs_preprocessing"):
        ensure_preprocessing(ticker, base_dir)

    transcript_file, session_dir = setup_session()
    transcript = TranscriptWriter(transcript_file)
    tracker = SubagentTracker(transcript_writer=transcript, session_dir=session_dir)

    hooks = {
        "PreToolUse": [
            HookMatcher(matcher=None, hooks=[tracker.pre_tool_use_hook]),
        ],
        "PostToolUse": [
            HookMatcher(matcher=None, hooks=[tracker.post_tool_use_hook]),
        ],
    }

    # Initialize SEC MCP server if agent uses SEC tools
    mcp_servers: dict[str, object] = {}
    if (
        "get_company_filings" in config["tools"]
        or "get_financial_snapshot" in config["tools"]
    ):
        sec_tool = SECAgentTool()
        mcp_servers["sec"] = build_sec_mcp_server(sec_tool)

    options = ClaudeAgentOptions(
        permission_mode="bypassPermissions",
        system_prompt=prompt,
        allowed_tools=config["tools"],
        hooks=hooks,
        mcp_servers=mcp_servers,
        model=model,
    )

    task_prompt = instruction or config["task_template"].format(ticker=ticker)

    print("\n" + "=" * 70)
    print(f"Running single agent: {agent_key} for {ticker}")
    print(f"Model: {model}")
    print(f"Session logs: {session_dir}")
    print(f"Instruction: {task_prompt}")
    print("=" * 70 + "\n")

    result_msg = None
    try:
        async with ClaudeSDKClient(options=options) as client:
            await client.query(prompt=task_prompt)
            transcript.write_to_file(f"\nUser: {task_prompt}\n")
            transcript.write("\nAgent: ", end="")

            async for msg in client.receive_response():
                msg_type = type(msg).__name__
                if msg_type == "AssistantMessage":
                    process_assistant_message(msg, tracker, transcript)
                elif isinstance(msg, ResultMessage):
                    result_msg = msg
                elif msg_type == "ContentBlockDelta":
                    # Streaming text delta
                    if hasattr(msg, "delta") and hasattr(msg.delta, "text"):
                        print(msg.delta.text, end="", flush=True)
                elif msg_type not in (
                    "ContentBlockStart",
                    "ContentBlockStop",
                    "MessageStart",
                    "MessageStop",
                ):
                    # Debug: show unknown message types
                    print(f"\n[DEBUG] Unknown msg type: {msg_type}", flush=True)

            transcript.write("\n")
    finally:
        transcript.write("\n\nSession complete.\n")
        transcript.close()
        tracker.close()
        print(f"\n{'='*70}")
        print("ğŸ“Š Session Summary")
        print(f"{'='*70}")
        print(f"Session logs: {session_dir}")
        print(f"  - Transcript: {transcript_file}")
        print(f"  - Tool calls: {session_dir / 'tool_calls.jsonl'}")

        # Display token usage and cost
        if result_msg:
            print(f"\nğŸ’° Cost & Usage:")
            if result_msg.total_cost_usd is not None:
                print(f"  - Total cost: ${result_msg.total_cost_usd:.4f}")
            if result_msg.usage:
                input_tokens = result_msg.usage.get("input_tokens", 0)
                output_tokens = result_msg.usage.get("output_tokens", 0)
                print(f"  - Input tokens: {input_tokens:,}")
                print(f"  - Output tokens: {output_tokens:,}")
                print(f"  - Total tokens: {input_tokens + output_tokens:,}")
            print(f"  - Turns: {result_msg.num_turns}")
            print(f"  - Duration: {result_msg.duration_ms / 1000:.1f}s")
        print("=" * 70 + "\n")
        write_session_notes(
            base_dir=base_dir,
            agent_key=agent_key,
            ticker=ticker,
            task_prompt=task_prompt,
            model=model,
            session_dir=session_dir,
            transcript_file=transcript_file,
        )


async def main():
    load_dotenv()
    if not os.environ.get("ANTHROPIC_API_KEY"):
        raise SystemExit(
            "Error: ANTHROPIC_API_KEY not found. Set it in your environment or .env file."
        )

    args = parse_args()
    ticker = (
        (args.ticker or input("Enter ticker symbol (e.g., NVDA): ")).strip().upper()
    )
    if not ticker:
        raise SystemExit("Ticker symbol is required.")

    await run_agent(
        agent_key=args.agent,
        ticker=ticker,
        model=args.model,
        instruction=args.instruction,
    )


if __name__ == "__main__":
    asyncio.run(main())
